{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef35b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки и модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c562556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import random\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0391024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем устройство для выполнения вычислений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7c509d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "seed = 42 #Устанавливаем случайное зерно для генератора псевдослучайных чисел для воспроизводимости результатов\n",
    "torch.manual_seed(seed)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b25cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем класс Dataset для загрузки и предобработки изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9e94e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "    # Определяем методы len и getitem для доступа к данным в Dataset\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.file_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img_transformed = self.transform(img)\n",
    "\n",
    "        label = os.path.split(os.path.split(img_path)[-2])[-1]\n",
    "        if label == 'Dog':\n",
    "            label = torch.tensor(1)\n",
    "        elif label == 'Cat':\n",
    "            label = torch.tensor(0)\n",
    "\n",
    "        return img_transformed, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87def3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем объект преобразований для предобработки изображений "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f241f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем путь к директории с изображениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69c7b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'PetImages'\n",
    "\n",
    "img_list = glob.glob(os.path.join(img_dir, '*/*.jpg')) # Создаем список файлов изображений с помощью функции glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03b5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем список файлов на обучающую и валидационную выборки с помощью функции train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d29d935",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, val_list = train_test_split(img_list, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74569a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем объекты Dataset для обучающей и валидационной выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dacf9591",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset(train_list, transform=transform)\n",
    "val_data = Dataset(val_list, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626c8ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем загрузчики данных для обучающей и валидационной выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22d6c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d91088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем класс модели сверточной нейронной сети с несколькими сверточными слоями и полносвязными слоями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca65d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cnn, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=0, stride=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=0, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=0, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(3 * 3 * 64, 10)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(10, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x): #Определяем метод forward, который определяет поток данных внутри модели\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5248935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем экземпляр модели и переносим его на устройство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9fcee50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cnn(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Linear(in_features=576, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Cnn().to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9acb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем оптимизатор и функцию потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1c0d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59c8edef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1, train accuracy : 0.8273997902870178, train loss : 0.38077840209007263\n",
      "Epoch : 1, val_accuracy : 0.8109079599380493, val_loss : 0.41418910026550293\n",
      "Epoch : 2, train accuracy : 0.851849377155304, train loss : 0.33566999435424805\n",
      "Epoch : 2, val_accuracy : 0.8144906759262085, val_loss : 0.4108200967311859\n",
      "Epoch : 3, train accuracy : 0.875150203704834, train loss : 0.2944703996181488\n",
      "Epoch : 3, val_accuracy : 0.8258362412452698, val_loss : 0.39464524388313293\n",
      "Epoch : 4, train accuracy : 0.8916997909545898, train loss : 0.2559053897857666\n",
      "Epoch : 4, val_accuracy : 0.8055335879325867, val_loss : 0.4616509974002838\n",
      "Epoch : 5, train accuracy : 0.9083508849143982, train loss : 0.22029808163642883\n",
      "Epoch : 5, val_accuracy : 0.8202627301216125, val_loss : 0.4712638258934021\n",
      "Epoch : 6, train accuracy : 0.9216514229774475, train loss : 0.19403323531150818\n",
      "Epoch : 6, val_accuracy : 0.8138935565948486, val_loss : 0.4873391091823578\n",
      "Epoch : 7, train accuracy : 0.9314520359039307, train loss : 0.1699630618095398\n",
      "Epoch : 7, val_accuracy : 0.8162822723388672, val_loss : 0.5093016624450684\n",
      "Epoch : 8, train accuracy : 0.9430028200149536, train loss : 0.1414063721895218\n",
      "Epoch : 8, val_accuracy : 0.8266323804855347, val_loss : 0.5128887891769409\n",
      "Epoch : 9, train accuracy : 0.9529538154602051, train loss : 0.11972152441740036\n",
      "Epoch : 9, val_accuracy : 0.8174763321876526, val_loss : 0.5573862195014954\n",
      "Epoch : 10, train accuracy : 0.9569540023803711, train loss : 0.1103212982416153\n",
      "Epoch : 10, val_accuracy : 0.8162819147109985, val_loss : 0.5860073566436768\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs): #Внутри цикла обучения выполняются итерации по обучающему загрузчику данных\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "\n",
    "    for data, label in train_loader: # Переносим данные и метки на устройство\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = model(data) #Получаем выход модели и вычисляем потерю\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        optimizer.zero_grad() # Обнуляем градиенты, выполняем обратное распространение ошибки и обновляем веса модели\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        acc = ((output.argmax(dim=1) == label).float().mean()) #Вычисляем точность и потерю на обучающей выборке\n",
    "        epoch_accuracy += acc / len(train_loader)\n",
    "        epoch_loss += loss / len(train_loader)\n",
    "\n",
    "    print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch + 1, epoch_accuracy, epoch_loss)) # Выводимрезультаты обучения на каждой эпохе\n",
    "# Вне цикла обучения выполняем валидацию модели на валидационном загрузчике данных\n",
    "    with torch.no_grad():\n",
    "        epoch_val_accuracy = 0\n",
    "        epoch_val_loss = 0\n",
    "        for data, label in val_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            val_output = model(data)\n",
    "            val_loss = criterion(val_output, label)\n",
    "\n",
    "            acc = ((val_output.argmax(dim=1) == label).float().mean())\n",
    "            epoch_val_accuracy += acc / len(val_loader)\n",
    "            epoch_val_loss += val_loss / len(val_loader)\n",
    "\n",
    "        print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch + 1, epoch_val_accuracy, epoch_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb0f68f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
